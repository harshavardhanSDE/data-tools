{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1L5OdhFCLvoyvgnvVsQNZXd4vUNTuaU8p",
      "authorship_tag": "ABX9TyMSd7QcNu/cuk45lyMygxYP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/harshavardhanSDE/data-tools/blob/main/Data_preprocessing_tools.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preprocessing Tools\n",
        "> Importing libraries <br>\n",
        "> Importing Dataset <br>\n",
        "> Taking care of Missing data <br>\n",
        "> Encoding categorical data <br>\n",
        "\n",
        "> > Encoding the independent variable <br>\n",
        "> > Encoding the dependent variable <br>\n",
        "\n",
        "> Splitting data in to training and test set <br>\n",
        "> Feature scaling"
      ],
      "metadata": {
        "id": "xxyaYnD3tHV1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data preprocessing `methods` avilable in `Pandas`."
      ],
      "metadata": {
        "id": "Uryj_cYexcwS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pandas is a popular Python library for data manipulation and analysis. It provides a wide range of functions and methods for data preprocessing. Here are some of the commonly used data preprocessing functions available in Pandas:\n",
        "\n",
        "1. **Loading Data:**\n",
        "   - `pd.read_csv()`: Read data from CSV files.\n",
        "   - `pd.read_excel()`: Read data from Excel files.\n",
        "   - `pd.read_sql()`: Read data from SQL databases.\n",
        "   - `pd.read_json()`: Read data from JSON files.\n",
        "\n",
        "2. **Handling Missing Data:**\n",
        "   - `df.dropna()`: Drop rows or columns with missing values.\n",
        "   - `df.fillna()`: Fill missing values with specified values or methods.\n",
        "   - `df.interpolate()`: Interpolate missing values based on linear or polynomial methods.\n",
        "\n",
        "3. **Data Transformation:**\n",
        "   - `df.apply()`: Apply a function along rows or columns.\n",
        "   - `df.map()`: Apply a function element-wise.\n",
        "   - `df.replace()`: Replace values with other values.\n",
        "   - `df.rename()`: Rename columns.\n",
        "   - `df.sort_values()`: Sort DataFrame by values.\n",
        "   - `df.groupby()`: Group data by specified columns and apply aggregation functions.\n",
        "\n",
        "4. **Categorical Data Handling:**\n",
        "   - `pd.get_dummies()`: Create one-hot encoded columns for categorical variables.\n",
        "   - `df.astype()`: Convert data types of columns.\n",
        "   - `df.cut()`: Bin continuous data into intervals.\n",
        "\n",
        "5. **String Manipulation:**\n",
        "   - `df.str.lower()`, `df.str.upper()`: Convert strings to lowercase/uppercase.\n",
        "   - `df.str.strip()`: Remove leading and trailing whitespace.\n",
        "   - `df.str.replace()`: Replace substrings in strings.\n",
        "\n",
        "6. **Datetime Handling:**\n",
        "   - `pd.to_datetime()`: Convert strings to datetime objects.\n",
        "   - `df.resample()`: Resample time series data to different frequencies.\n",
        "   - `df.shift()`: Shift data along the time axis.\n",
        "\n",
        "7. **Data Aggregation and Transformation:**\n",
        "   - `df.groupby()`: Group data and perform aggregation operations.\n",
        "   - `df.pivot_table()`: Create pivot tables for summarizing data.\n",
        "   - `df.melt()`: Convert wide data to long format.\n",
        "\n",
        "8. **Combining Data:**\n",
        "   - `pd.concat()`: Concatenate DataFrames along rows or columns.\n",
        "   - `pd.merge()`: Merge DataFrames based on specified keys.\n",
        "\n",
        "9. **Feature Scaling and Normalization:**\n",
        "   - These operations can be performed using mathematical operations and broadcasting on DataFrame columns.\n",
        "\n",
        "10. **Dropping Columns:**\n",
        "    - `df.drop()`: Drop specified columns.\n",
        "\n",
        "11. **Dropping Duplicate Rows:**\n",
        "    - `df.drop_duplicates()`: Remove duplicate rows.\n",
        "\n",
        "12. **Indexing and Selection:**\n",
        "    - Selecting rows and columns using indexing and boolean conditions.\n",
        "\n",
        "13. **Data Visualization:**\n",
        "    - Pandas can work well with other visualization libraries like Matplotlib and Seaborn for exploratory data analysis.\n",
        "\n",
        "These are just a subset of the many functions and methods provided by Pandas for data preprocessing. Depending on your specific data and preprocessing needs, you can combine these functions to create powerful data transformation pipelines."
      ],
      "metadata": {
        "id": "tI8-EJvOxrno"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importing Libraries."
      ],
      "metadata": {
        "id": "dJdNjHh9tqSE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "urCP7KY6wE3h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importing Dataset"
      ],
      "metadata": {
        "id": "jp96jzTmtu5L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/Machine Learning A-Z (Codes and Datasets)/Part 1 - Data Preprocessing/Section 2 -------------------- Part 1 - Data Preprocessing --------------------/Python/Data.csv\")\n",
        "feature_matrix_x = dataset.iloc[:, :-1].values\n",
        "dependent_variable_y = dataset.iloc[:, -1].values"
      ],
      "metadata": {
        "id": "lmAUuNzr1pYO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Printing values:\n",
        "print(feature_matrix_x, dependent_variable_y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uf32n_p38QnN",
        "outputId": "1912a715-9b00-45ac-9083-d05f5d5a55bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['France' 44.0 72000.0]\n",
            " ['Spain' 27.0 48000.0]\n",
            " ['Germany' 30.0 54000.0]\n",
            " ['Spain' 38.0 61000.0]\n",
            " ['Germany' 40.0 nan]\n",
            " ['France' 35.0 58000.0]\n",
            " ['Spain' nan 52000.0]\n",
            " ['France' 48.0 79000.0]\n",
            " ['Germany' 50.0 83000.0]\n",
            " ['France' 37.0 67000.0]] ['No' 'Yes' 'No' 'No' 'Yes' 'Yes' 'No' 'Yes' 'No' 'Yes']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fb1YGMJ7FFtm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## `Indexing and Selection`\n",
        "\n",
        "Advanced indexing and selecting in Python, particularly when working with NumPy arrays and Pandas DataFrames, allows you to access and manipulate data using more complex indexing methods. This includes using boolean masks, integer arrays, and multi-dimensional indexing. Let's explore advanced indexing and selection techniques in both NumPy and Pandas:\n",
        "\n",
        "### NumPy:\n",
        "\n",
        "1. **Boolean Indexing:**\n",
        "   You can use boolean arrays to select elements that satisfy a certain condition.\n",
        "   ```python\n",
        "   import numpy as np\n",
        "\n",
        "   arr = np.array([1, 2, 3, 4, 5])\n",
        "   mask = arr > 2\n",
        "   selected = arr[mask]  # [3, 4, 5]\n",
        "   ```\n",
        "\n",
        "2. **Fancy Indexing:**\n",
        "   Using arrays of indices to select elements from an array.\n",
        "   ```python\n",
        "   arr = np.array([1, 2, 3, 4, 5])\n",
        "   indices = np.array([0, 3])\n",
        "   selected = arr[indices]  # [1, 4]\n",
        "   ```\n",
        "\n",
        "3. **Multi-dimensional Indexing:**\n",
        "   Accessing elements in multi-dimensional arrays.\n",
        "   ```python\n",
        "   arr = np.array([[1, 2, 3], [4, 5, 6]])\n",
        "   element = arr[1, 2]  # 6\n",
        "   ```\n",
        "\n",
        "### Pandas:\n",
        "\n",
        "1. **Boolean Indexing:**\n",
        "   Applying boolean masks to DataFrames to filter rows.\n",
        "   ```python\n",
        "   import pandas as pd\n",
        "\n",
        "   df = pd.DataFrame({'A': [1, 2, 3], 'B': [4, 5, 6]})\n",
        "   mask = df['A'] > 1\n",
        "   selected_rows = df[mask]\n",
        "   ```\n",
        "\n",
        "2. **Label-based Indexing:**\n",
        "   Selecting rows and columns by labels using `.loc`.\n",
        "   ```python\n",
        "   selected = df.loc[1, 'B']\n",
        "   selected_rows = df.loc[df['A'] > 1]\n",
        "   ```\n",
        "\n",
        "3. **Position-based Indexing:**\n",
        "   Selecting rows and columns by integer positions using `.iloc`.\n",
        "   ```python\n",
        "   selected = df.iloc[0, 1]\n",
        "   selected_rows = df.iloc[1:]\n",
        "   ```\n",
        "\n",
        "4. **Indexing with MultiIndex:**\n",
        "   Dealing with multi-level indexing in DataFrames.\n",
        "   ```python\n",
        "   df = pd.DataFrame({'A': [1, 2, 3]}, index=[['X', 'X', 'Y'], [1, 2, 1]])\n",
        "   selected = df.loc['X', 1]\n",
        "   ```\n",
        "\n",
        "5. **Using `loc` and `iloc` for Mixed Selection:**\n",
        "   Combining label-based and position-based indexing for selection.\n",
        "   ```python\n",
        "   selected = df.loc['X'].iloc[0]\n",
        "   ```\n",
        "\n",
        "6. **Indexing and Selection with `.xs()`:**\n",
        "   Cross-section selection from hierarchical indices.\n",
        "   ```python\n",
        "   xs_selected = df.xs('X', level=0)\n",
        "   ```\n",
        "\n",
        "Advanced indexing and selecting are powerful techniques that allow you to extract, modify, and analyze specific portions of data from arrays and DataFrames based on different conditions and positions. These methods are essential for performing more complex data manipulation and analysis tasks."
      ],
      "metadata": {
        "id": "wn_IAwyR13Wp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Taking care of Missing data"
      ],
      "metadata": {
        "id": "2fkPxIaXuAHB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# using the impute module of scikit learn to fill the missing value.\n",
        "from sklearn.impute import SimpleImputer\n",
        "imputer = SimpleImputer(strategy=\"mean\")\n",
        "feature_matrix_x[:, 1:3] = imputer.fit_transform(feature_matrix_x[:, 1:3])"
      ],
      "metadata": {
        "id": "ZPsFJfVlFIae"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(feature_matrix_x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tAy-23AlKczW",
        "outputId": "837d4ef7-d687-425c-b0bd-6cf0ee7c2693"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['France' 44.0 72000.0]\n",
            " ['Spain' 27.0 48000.0]\n",
            " ['Germany' 30.0 54000.0]\n",
            " ['Spain' 38.0 61000.0]\n",
            " ['Germany' 40.0 63777.77777777778]\n",
            " ['France' 35.0 58000.0]\n",
            " ['Spain' 38.77777777777778 52000.0]\n",
            " ['France' 48.0 79000.0]\n",
            " ['Germany' 50.0 83000.0]\n",
            " ['France' 37.0 67000.0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Encoding Categorical data."
      ],
      "metadata": {
        "id": "PXB1U91ZuFyi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Encoding the Independent variable"
      ],
      "metadata": {
        "id": "9vy6HI2zuLTx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "cTransformer = ColumnTransformer(transformers=[(\"encoder\", OneHotEncoder(), [0])], remainder=\"passthrough\")\n",
        "feature_matrix_x = np.array(cTransformer.fit_transform(feature_matrix_x))"
      ],
      "metadata": {
        "id": "D2WDAoLPWuIF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(feature_matrix_x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p6hAitUqYL3s",
        "outputId": "f841eba5-b8cd-4cc6-af6b-8b1f30b8e514"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1.0 0.0 0.0 44.0 72000.0]\n",
            " [0.0 0.0 1.0 27.0 48000.0]\n",
            " [0.0 1.0 0.0 30.0 54000.0]\n",
            " [0.0 0.0 1.0 38.0 61000.0]\n",
            " [0.0 1.0 0.0 40.0 63777.77777777778]\n",
            " [1.0 0.0 0.0 35.0 58000.0]\n",
            " [0.0 0.0 1.0 38.77777777777778 52000.0]\n",
            " [1.0 0.0 0.0 48.0 79000.0]\n",
            " [0.0 1.0 0.0 50.0 83000.0]\n",
            " [1.0 0.0 0.0 37.0 67000.0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Encoding the dependent variable"
      ],
      "metadata": {
        "id": "b3V2H6j8uV_z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "Ltransformer = LabelEncoder()\n",
        "dependent_variable_y = Ltransformer.fit_transform(dependent_variable_y)\n"
      ],
      "metadata": {
        "id": "-TqShugCYRmo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(dependent_variable_y)"
      ],
      "metadata": {
        "id": "y5fgecIUY4Ml",
        "outputId": "96f2385f-eb0a-4f7b-e5d3-61f0f4145892",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 1 0 0 1 1 0 1 0 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Splitting data in to training & test set."
      ],
      "metadata": {
        "id": "cWGU5gP6uceB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "feature_matrix_x_train, feature_matrix_x_test, dependent_variable_y_train, dependent_variable_y_test = train_test_split(feature_matrix_x, dependent_variable_y, test_size = 0.2, random_state = 1)"
      ],
      "metadata": {
        "id": "r165GK5rKPsi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"xtrain:{feature_matrix_x_train}\" )\n",
        "print(f\"xtest: {feature_matrix_x_test}\")\n",
        "print(f\"ytrain:{dependent_variable_y_train}\")\n",
        "print(f\"ytest:{dependent_variable_y_test}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H2sMei3yNrFd",
        "outputId": "9682e26e-ecf1-4323-b7db-db410aa2c135"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "xtrain:[[0.0 0.0 1.0 38.77777777777778 52000.0]\n",
            " [0.0 1.0 0.0 40.0 63777.77777777778]\n",
            " [1.0 0.0 0.0 44.0 72000.0]\n",
            " [0.0 0.0 1.0 38.0 61000.0]\n",
            " [0.0 0.0 1.0 27.0 48000.0]\n",
            " [1.0 0.0 0.0 48.0 79000.0]\n",
            " [0.0 1.0 0.0 50.0 83000.0]\n",
            " [1.0 0.0 0.0 35.0 58000.0]]\n",
            "xtest: [[0.0 1.0 0.0 30.0 54000.0]\n",
            " [1.0 0.0 0.0 37.0 67000.0]]\n",
            "ytrain:[0 1 0 0 1 1 0 1]\n",
            "ytest:[0 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feature Scaling"
      ],
      "metadata": {
        "id": "JOXP4eZoum44"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "sScaler = StandardScaler()\n",
        "feature_matrix_x_train[:, 3:] = sScaler.fit_transform(feature_matrix_x[:, 3:])\n",
        "feature_matrix_x_test[:, 3:] = sScaler.transform(feature_matrix_x_test[:, 3:])"
      ],
      "metadata": {
        "id": "FF07jZX3csHp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}